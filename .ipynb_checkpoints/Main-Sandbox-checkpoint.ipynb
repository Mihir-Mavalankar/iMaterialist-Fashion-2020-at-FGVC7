{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T23:50:26.504856Z",
     "start_time": "2020-05-04T23:50:21.395714Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "import pickle\n",
    "import joblib\n",
    "import cv2\n",
    "#import bz2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T23:50:32.293168Z",
     "start_time": "2020-05-04T23:50:32.281168Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    DATA_PATH = 'data/imaterialist-fashion-2020-fgvc7'\n",
    "    IMAGE_SIZE = 256\n",
    "    NO_OF_CLASSES = 46\n",
    "    BATCH_SIZE = 8\n",
    "    OUTPUT_MASK_SIZE=256\n",
    "    RESIZE=True\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T23:50:52.098265Z",
     "start_time": "2020-05-04T23:50:33.345181Z"
    }
   },
   "outputs": [],
   "source": [
    "conf = Config()\n",
    "train_df = pd.read_csv(conf.DATA_PATH+'/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T23:51:25.984806Z",
     "start_time": "2020-05-04T23:51:22.262527Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataloader import iMetDataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T23:51:32.794821Z",
     "start_time": "2020-05-04T23:51:32.684855Z"
    }
   },
   "outputs": [],
   "source": [
    "d = iMetDataset_2(conf, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T23:54:52.173583Z",
     "start_time": "2020-05-04T23:54:48.589103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         ...,\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529]],\n",
       " \n",
       "        [[0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         ...,\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529]],\n",
       " \n",
       "        [[0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         ...,\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         ...,\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529]],\n",
       " \n",
       "        [[0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         ...,\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529]],\n",
       " \n",
       "        [[0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         ...,\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529],\n",
       "         [0.81568627, 0.81960784, 0.78823529]]]),\n",
       " {'boxes': array([[1163, 3923, 2839, 5212],\n",
       "         [1212, 1371, 2394, 3978],\n",
       "         [1634, 1371, 2394, 1891],\n",
       "         [2474, 1827, 3309, 4602],\n",
       "         [2078, 2509, 2577, 2662],\n",
       "         [2198, 3758, 2672, 4028],\n",
       "         [1133, 1779, 1494, 3162],\n",
       "         [1231, 1437, 2523, 3386],\n",
       "         [ 875, 1437, 3309, 4871]]),\n",
       "  'labels': array([ 6,  0, 28, 31, 32, 32, 31, 29,  4]),\n",
       "  'masks': array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "         [[0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0],\n",
       "          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
       "  'image_id': array([0])})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T19:38:41.259577Z",
     "start_time": "2020-05-03T19:38:41.197597Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class iMetDataset(object):\n",
    "    def __init__(self, config, df, random_seed=0):       # transforms,\n",
    "        self.CONFIG = config\n",
    "        self.TRAINING_DATA_PATH = self.CONFIG.DATA_PATH + '/train/'\n",
    "        self.TRAINING_DATA_FRAME = df\n",
    "        #self.transforms = transforms\n",
    "        # load all image files, sorting them to\n",
    "        # ensure that they are aligned\n",
    "        self.imgs = self.TRAINING_DATA_FRAME.ImageId.unique()\n",
    "        np.random.seed(random_seed)\n",
    "        \n",
    "    def make_single_mask(self, encoded_string, height, width):\n",
    "        splitted_string = np.array(list(map(int, encoded_string.split()))).reshape(-1,2)\n",
    "        mask = np.zeros((height*width), dtype=np.uint8)\n",
    "        for start_indice, run_length in splitted_string:\n",
    "            start_indice-=1\n",
    "            mask[start_indice:start_indice+run_length] = 1\n",
    "        return mask.reshape((height, width), order='F')\n",
    "    \n",
    "    def get_box(self, mask):\n",
    "        w = np.sum(mask, axis=0)\n",
    "        h = np.sum(mask, axis=1)\n",
    "        x1, x2 = 0, len(w)-1\n",
    "        y1, y2 = 0, len(h)-1\n",
    "        while w[x1]==0:\n",
    "            x1+=1\n",
    "        while w[x2]==0:\n",
    "            x2-=1\n",
    "        while h[y1]==0:\n",
    "            y1+=1\n",
    "        while h[y2]==0:\n",
    "            y2-=1\n",
    "        return np.array([x1, y1, x2, y2])\n",
    "    \n",
    "    def get_ground_truth(self, image_id):\n",
    "        query = self.TRAINING_DATA_FRAME[self.TRAINING_DATA_FRAME.ImageId==image_id]\n",
    "        encoded_pixels = query.EncodedPixels\n",
    "        class_ids = query.ClassId\n",
    "        height, width = list(query.Height)[0], list(query.Width)[0]\n",
    "        \n",
    "        masks=[]\n",
    "        labels=[]\n",
    "        boxes=[]\n",
    "            \n",
    "        for _, (encoded_pixel_str, class_id) in enumerate(zip(encoded_pixels, class_ids)):\n",
    "            sub_mask = self.make_single_mask(encoded_pixel_str, height, width)\n",
    "            masks.append(sub_mask)\n",
    "            boxes.append(self.get_box(sub_mask))\n",
    "            labels.append(class_id)\n",
    "            \n",
    "        return {'boxes':torch.as_tensor(boxes, dtype=torch.float32), \n",
    "                'labels': torch.as_tensor(labels, dtype=torch.int64), \n",
    "                'masks': torch.as_tensor(masks, dtype=torch.uint8)}\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images ad masks\n",
    "        img_path = self.TRAINING_DATA_PATH + self.imgs[idx] + '.jpg'\n",
    "        img = torch.tensor(cv2.cvtColor( cv2.imread(img_path), cv2.COLOR_BGR2RGB)/255)\n",
    "        \n",
    "        target = self.get_ground_truth(self.imgs[idx])\n",
    "        \n",
    "        image_id = torch.tensor([idx])\n",
    "        target[\"image_id\"] = image_id\n",
    "        \n",
    "        boxes = target['boxes']\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        target[\"area\"] = area\n",
    "    \n",
    "        #if self.transforms is not None:\n",
    "        #    img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:23:58.752667Z",
     "start_time": "2020-05-02T21:23:58.668695Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset_for_pytorch():\n",
    "    def __init__ (self, config, df, random_seed=0):\n",
    "        self.CONFIG = config\n",
    "        self.TRAINING_DATA_PATH = self.CONFIG.DATA_PATH + '/train/'\n",
    "        self.TRAINING_DATA_FRAME = df\n",
    "        self.DATASET_IDXS = self.TRAINING_DATA_FRAME.ImageId.unique()\n",
    "        self.DATASET_SIZE = self.DATASET_IDXS.shape[0]\n",
    "        \n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(self.DATASET_IDXS)\n",
    "        self.CURRENT_IDX=0\n",
    "        \n",
    "    def get_image(self, image_id, resize=True):\n",
    "        img = cv2.cvtColor( cv2.imread(self.TRAINING_DATA_PATH+image_id+'.jpg'), cv2.COLOR_BGR2RGB)\n",
    "        if resize:\n",
    "            return cv2.resize(img, \n",
    "                              (self.CONFIG.IMAGE_SIZE, self.CONFIG.IMAGE_SIZE), \n",
    "                              interpolation = cv2.INTER_NEAREST)/255\n",
    "        else:\n",
    "            return img/255\n",
    "        \n",
    "    def make_single_mask(self, encoded_string, height, width):\n",
    "        splitted_string = np.array(list(map(int, encoded_string.split()))).reshape(-1,2)\n",
    "        mask = np.zeros((height*width), dtype=np.uint8)\n",
    "        for start_indice, run_length in splitted_string:\n",
    "            start_indice-=1\n",
    "            mask[start_indice:start_indice+run_length] = 1\n",
    "        return mask.reshape((height, width), order='F')\n",
    "    \n",
    "    def get_box(self, mask):\n",
    "        w = np.sum(mask, axis=0)\n",
    "        h = np.sum(mask, axis=1)\n",
    "        x1, x2 = 0, len(w)-1\n",
    "        y1, y2 = 0, len(h)-1\n",
    "        while w[x1]==0:\n",
    "            x1+=1\n",
    "        while w[x2]==0:\n",
    "            x2-=1\n",
    "        while h[y1]==0:\n",
    "            y1+=1\n",
    "        while h[y2]==0:\n",
    "            y2-=1\n",
    "\n",
    "        return np.array([x1, y1, x2, y2])\n",
    "    \n",
    "    def get_ground_truth(self, image_id, resize=True):\n",
    "        \n",
    "        query = self.TRAINING_DATA_FRAME[self.TRAINING_DATA_FRAME.ImageId==image_id]\n",
    "        encoded_pixels = query.EncodedPixels\n",
    "        class_ids = query.ClassId\n",
    "        height, width = list(query.Height)[0], list(query.Width)[0]\n",
    "        \n",
    "        masks=[]\n",
    "        labels=[]\n",
    "        boxes=[]\n",
    "            \n",
    "        for _, (encoded_pixel_str, class_id) in enumerate(zip(encoded_pixels, class_ids)):\n",
    "            sub_mask = self.make_single_mask(encoded_pixel_str, height, width)\n",
    "            if resize:\n",
    "                sub_mask = cv2.resize(sub_mask, \n",
    "                                      (self.CONFIG.OUTPUT_MASK_SIZE, self.CONFIG.OUTPUT_MASK_SIZE), \n",
    "                                      interpolation=cv2.INTER_NEAREST)\n",
    "            masks.append(sub_mask)\n",
    "            boxes.append(self.get_box(sub_mask))\n",
    "            labels.append(class_id)\n",
    "            \n",
    "        return {'boxes':np.array(boxes), \n",
    "                'labels': np.array(labels), \n",
    "                'masks': np.array(masks)}\n",
    "    \n",
    "    \n",
    "    def sample_next_batch(self):\n",
    "        next_idx = self.CURRENT_IDX+self.CONFIG.BATCH_SIZE\n",
    "        if next_idx>self.DATASET_SIZE-1:\n",
    "            next_idx = self.CONFIG.BATCH_SIZE-(self.DATASET_SIZE-self.CURRENT_IDX)\n",
    "            batch_idxs = np.concatenate((self.DATASET_IDXS[self.CURRENT_IDX:], \n",
    "                                        self.DATASET_IDXS[:next_idx]))\n",
    "            self.CURRENT_IDX = next_idx\n",
    "            return batch_idxs, True\n",
    "        else:\n",
    "            batch_idxs = self.DATASET_IDXS[self.CURRENT_IDX:next_idx]\n",
    "            self.CURRENT_IDX = next_idx\n",
    "            return batch_idxs, False\n",
    "    \n",
    "    def get_next_batch(self, resize=True):\n",
    "        batch_idxs, epoch_finish = self.sample_next_batch()\n",
    "        print(batch_idxs)\n",
    "        train_images=[]\n",
    "        ground_truth=[]\n",
    "        for image_id in batch_idxs:\n",
    "            train_images.append(self.get_image(image_id, resize=resize))\n",
    "            ground_truth.append(self.get_ground_truth(image_id, resize=resize))\n",
    "        return train_images, ground_truth, epoch_finish\n",
    "            \n",
    "    def get_label_dictionaries(self):\n",
    "        json_file = json.loads(open(self.CONFIG.DATA_PATH+'/label_descriptions.json', 'r').read())\n",
    "        categories = {id_:category \n",
    "                      for (id_,category) \n",
    "                      in zip([i['id'] for i in json_file['categories']], \n",
    "                             [n['name'] for n in json_file['categories']])}\n",
    "        attributes = {id_:category \n",
    "                      for (id_,category) \n",
    "                      in zip([i['id'] for i in json_file['attributes']], \n",
    "                             [n['name'] for n in json_file['attributes']])}\n",
    "        return categories, attributes\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.get_next_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T19:20:46.980510Z",
     "start_time": "2020-05-02T19:20:46.964392Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T19:20:53.310901Z",
     "start_time": "2020-05-02T19:20:48.319097Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
       "    )\n",
       "    (mask_roi_pool): MultiScaleRoIAlign()\n",
       "    (mask_head): MaskRCNNHeads(\n",
       "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu3): ReLU(inplace=True)\n",
       "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu4): ReLU(inplace=True)\n",
       "    )\n",
       "    (mask_predictor): MaskRCNNPredictor(\n",
       "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (mask_fcn_logits): Conv2d(256, 91, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T19:20:56.991146Z",
     "start_time": "2020-05-02T19:20:56.971873Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T19:21:11.460208Z",
     "start_time": "2020-05-02T19:21:11.413098Z"
    }
   },
   "outputs": [],
   "source": [
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "def get_prediction(img_path, threshold):\n",
    "    img = Image.open(img_path)\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    img = transform(img)\n",
    "    pred = model([img])\n",
    "    pred_score = list(pred[0]['scores'].detach().numpy())\n",
    "    pred_t = [pred_score.index(x) for x in pred_score if x>threshold][-1]\n",
    "    masks = (pred[0]['masks']>0.5).squeeze().detach().cpu().numpy()\n",
    "    pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].numpy())]\n",
    "    pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().numpy())]\n",
    "    masks = masks[:pred_t+1]\n",
    "    pred_boxes = pred_boxes[:pred_t+1]\n",
    "    pred_class = pred_class[:pred_t+1]\n",
    "    return masks, pred_boxes, pred_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T20:05:23.917587Z",
     "start_time": "2020-05-02T20:05:16.498990Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "..\\torch\\csrc\\utils\\python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms as T\n",
    "a,b,c = get_prediction(config.DATA_PATH+'/train/'+train_df[train_df.columns[0]][0]+'.jpg', .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
